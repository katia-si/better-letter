{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text from Ist-oder-soll.jpeg has been saved in: /Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text/Ist-oder-soll.txt.\n",
      "Text from 1000014342.jpg has been saved in: /Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text/1000014342.txt.\n",
      "Text from letter_school_hamburg.png has been saved in: /Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text/letter_school_hamburg.txt.\n",
      "Text from 1000014343.jpg has been saved in: /Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text/1000014343.txt.\n",
      "Text from letter_arbeitsamt_internet.jpeg has been saved in: /Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text/letter_arbeitsamt_internet.txt.\n"
     ]
    }
   ],
   "source": [
    "### This part scans an image of letter and applies an OCR text recognition in order\n",
    "### to get the text of the image and transforms it to txt and stores it\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import easyocr\n",
    "\n",
    "def process_images(image_directory, output_directory):\n",
    "    \"\"\"\n",
    "    Process all images in the specified directory using OCR and save the extracted text to text files.\n",
    "\n",
    "    Args:\n",
    "        image_directory (str): Path to the directory containing the image files.\n",
    "        output_directory (str): Path to the directory where the output text files will be saved.\n",
    "    \"\"\"\n",
    "    # initialize the OCR reader\n",
    "    reader = easyocr.Reader(['de'])\n",
    "\n",
    "    # create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # iterate through all files in the directory\n",
    "    for filename in os.listdir(image_directory):\n",
    "        # check if file is an image\n",
    "        if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png') or filename.endswith('.pdf'):\n",
    "            # make the full path to the image file\n",
    "            image_path = os.path.join(image_directory, filename)\n",
    "\n",
    "            # open image for OCR\n",
    "            try:\n",
    "                with open(image_path, 'rb') as image_file:\n",
    "                    image_bytes = image_file.read()\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # extract text from image using easyocr\n",
    "            try:\n",
    "                result = reader.readtext(image_bytes)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # extracted text\n",
    "            text = '\\n'.join([entry[1] for entry in result])\n",
    "\n",
    "            # define output path to save extracted text\n",
    "            output_path = os.path.join(output_directory, f'{os.path.splitext(filename)[0]}.txt')\n",
    "\n",
    "            # check if output file already exists\n",
    "            if os.path.exists(output_path):\n",
    "                print(f\"Skipping {filename}. Output file {output_path} already exists.\")\n",
    "                continue\n",
    "\n",
    "            # save extracted text to a text file\n",
    "            with open(output_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(text)\n",
    "\n",
    "            # print a confirmation message about the text extraction\n",
    "            print(f'Text from {filename} has been saved in: {output_path}.')\n",
    "\n",
    "# define path to the directory containing the image files\n",
    "image_directory = '/Users/carstenvolland/code/katia-si/better-letter/text_extractor/data_images/'\n",
    "\n",
    "# define the path to the directory where the output text files will be saved\n",
    "output_directory = '/Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text'\n",
    "\n",
    "# process images in the specified directory\n",
    "process_images(image_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned text has been saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text_cleaned/1000014343_cldn.txt\n",
      "Cleaned text has been saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text_cleaned/1000014342_cldn.txt\n",
      "Cleaned text has been saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text_cleaned/letter_school_hamburg_cldn.txt\n",
      "Cleaned text has been saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text_cleaned/Ist-oder-soll_cldn.txt\n",
      "Cleaned text has been saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text_cleaned/letter_arbeitsamt_internet_cldn.txt\n"
     ]
    }
   ],
   "source": [
    "### this part cleans the text data from the letters from intendation or hyphenation and so on\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "def clean_extracted_text(text):\n",
    "    # Handle hyphenated line breaks\n",
    "    text = re.sub(r'(\\w+)-\\n(\\w+)', r'\\1\\2', text)\n",
    "    # Replace remaining newlines with spaces\n",
    "    text = text.replace('\\n', ' ')\n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def clean_and_save_files(input_directory, output_directory):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # Iterate through all files in the input directory\n",
    "    for filename in os.listdir(input_directory):\n",
    "        # Check if the file is a text file\n",
    "        if filename.endswith('.txt'):\n",
    "            # Construct the full path to the input file\n",
    "            input_file_path = os.path.join(input_directory, filename)\n",
    "            # Construct the full path to the output file\n",
    "            output_file_path = os.path.join(output_directory, filename.replace('.txt', '_cldn.txt'))\n",
    "\n",
    "            # Check if the output file already exists\n",
    "            if os.path.exists(output_file_path):\n",
    "                print(f'Skipping {filename}. Output file {output_file_path} already exists.')\n",
    "                continue\n",
    "\n",
    "            # Read the content of the input file\n",
    "            with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "                extracted_text = file.read()\n",
    "\n",
    "            # Clean the extracted text\n",
    "            cleaned_text = clean_extracted_text(extracted_text)\n",
    "\n",
    "            # Write the cleaned text to the output file\n",
    "            with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(cleaned_text)\n",
    "\n",
    "            print(f'Cleaned text has been saved to: {output_file_path}')\n",
    "\n",
    "# Define the input directory containing the extracted text files\n",
    "input_directory = '/Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text'\n",
    "\n",
    "# Define the output directory where cleaned text files will be saved\n",
    "output_directory = '/Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text_cleaned'\n",
    "\n",
    "# Clean and save text files in the input directory\n",
    "clean_and_save_files(input_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translated text has been saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/english_translation/letter_arbeitsamt_internet_cldn_en.txt\n",
      "translated text has been saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/english_translation/1000014342_cldn_en.txt\n",
      "translated text has been saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/english_translation/1000014343_cldn_en.txt\n",
      "translated text has been saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/english_translation/Ist-oder-soll_cldn_en.txt\n",
      "translated text has been saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/english_translation/letter_school_hamburg_cldn_en.txt\n"
     ]
    }
   ],
   "source": [
    "### translate letter from german to english\n",
    "\n",
    "import os\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# load pre-trained model and tokenizer\n",
    "model_name = \"Helsinki-NLP/opus-mt-de-en\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# function to translate German text to English\n",
    "def translate_german_to_english(text):\n",
    "    # tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "\n",
    "    # perform translation\n",
    "    translated = model.generate(**inputs)\n",
    "\n",
    "    # decode the translated text\n",
    "    translated_text = tokenizer.batch_decode(translated, skip_special_tokens=True)[0]\n",
    "\n",
    "    return translated_text\n",
    "\n",
    "# define input and output directories\n",
    "input_directory = '/Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text_cleaned'\n",
    "output_directory = '/Users/carstenvolland/code/katia-si/better-letter/raw_data/english_translation'\n",
    "\n",
    "# create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# translate and save each file in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    # check if the file is a text file\n",
    "    if filename.endswith('.txt'):\n",
    "        # construct the full path to the input file\n",
    "        input_file_path = os.path.join(input_directory, filename)\n",
    "\n",
    "        # construct the full path to the output file\n",
    "        output_file_path = os.path.join(output_directory, filename.replace('.txt', '_en.txt'))\n",
    "\n",
    "        # check if the output file already exists\n",
    "        if os.path.exists(output_file_path):\n",
    "            print(f'skipping {filename}. output file {output_file_path} already exists.')\n",
    "            continue\n",
    "\n",
    "        # read the content of the input file\n",
    "        with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "            german_text = file.read()\n",
    "\n",
    "        # translate german text to english\n",
    "        english_translation = translate_german_to_english(german_text)\n",
    "\n",
    "        # write english translation to the output file\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "            output_file.write(english_translation)\n",
    "\n",
    "        print(f'translated text has been saved to: {output_file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary has been generated and saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/english_summary/letter_school_hamburg_cldn_en_sum.txt\n",
      "summary has been generated and saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/english_summary/letter_arbeitsamt_internet_cldn_en_sum.txt\n",
      "summary has been generated and saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/english_summary/1000014343_cldn_en_sum.txt\n",
      "summary has been generated and saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/english_summary/Ist-oder-soll_cldn_en_sum.txt\n",
      "summary has been generated and saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/english_summary/1000014342_cldn_en_sum.txt\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "import os\n",
    "\n",
    "# load pre-trained model and tokenizer\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# function to generate summary\n",
    "def generate_summary(text):\n",
    "    inputs = tokenizer([text], max_length=1024, return_tensors='pt', truncation=True)\n",
    "    summary_ids = model.generate(inputs['input_ids'], num_beams=4, min_length=30, max_length=200, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# define input and output directories\n",
    "input_directory = '/Users/carstenvolland/code/katia-si/better-letter/raw_data/english_translation'\n",
    "output_directory = '/Users/carstenvolland/code/katia-si/better-letter/raw_data/english_summary'\n",
    "\n",
    "# create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# generate summary for each file in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    # check if file is a text file\n",
    "    if filename.endswith('.txt'):\n",
    "        # construct the full path to the input file\n",
    "        input_file_path = os.path.join(input_directory, filename)\n",
    "\n",
    "        # construct the full path to the output file\n",
    "        output_file_path = os.path.join(output_directory, f'{os.path.splitext(filename)[0]}_sum.txt')\n",
    "\n",
    "        # check if the output file already exists\n",
    "        if os.path.exists(output_file_path):\n",
    "            print(f'skipping {filename}. output file {output_file_path} already exists.')\n",
    "            continue\n",
    "\n",
    "        # read the content of the input file\n",
    "        with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        # generate summary\n",
    "        summary = generate_summary(text)\n",
    "\n",
    "        # write summary to the output file\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "            output_file.write(summary)\n",
    "\n",
    "        print(f'summary has been generated and saved to: {output_file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary has been generated and saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/german_summary_long/letter_arbeitsamt_internet_cldn_sum.txt\n",
      "summary has been generated and saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/german_summary_long/1000014342_cldn_sum.txt\n",
      "summary has been generated and saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/german_summary_long/1000014343_cldn_sum.txt\n",
      "summary has been generated and saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/german_summary_long/Ist-oder-soll_cldn_sum.txt\n",
      "summary has been generated and saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/german_summary_long/letter_school_hamburg_cldn_sum.txt\n"
     ]
    }
   ],
   "source": [
    "### trying a longer summarization\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import os\n",
    "\n",
    "# load pre-trained BART model and tokenizer for German\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Shahm/bart-german\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Shahm/bart-german\")\n",
    "\n",
    "# function to generate summary with adjusted parameters\n",
    "def generate_summary_longer(text: str) -> str:\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "    summary_ids = model.generate(\n",
    "        inputs,\n",
    "        max_length=400,  # increase max_length to make the summary longer\n",
    "        min_length=150,  # adjust min_length accordingly\n",
    "        length_penalty=2.0,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# define input and output directories\n",
    "input_directory = '/Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text_cleaned/'\n",
    "output_directory = '/Users/carstenvolland/code/katia-si/better-letter/raw_data/german_summary_long/'\n",
    "\n",
    "# create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# generate summary for each file in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    # check if file is a text file\n",
    "    if filename.endswith('.txt'):\n",
    "        # construct the full path to the input file\n",
    "        input_file_path = os.path.join(input_directory, filename)\n",
    "\n",
    "        # construct the full path to the output file\n",
    "        output_file_path = os.path.join(output_directory, f'{os.path.splitext(filename)[0]}_sum.txt')\n",
    "\n",
    "        # check if the output file already exists\n",
    "        if os.path.exists(output_file_path):\n",
    "            print(f'skipping {filename}. output file {output_file_path} already exists.')\n",
    "            continue\n",
    "\n",
    "        # read the content of the input file\n",
    "        with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        # generate summary\n",
    "        summary = generate_summary_longer(text)\n",
    "\n",
    "        # write summary to the output file\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "            output_file.write(summary)\n",
    "\n",
    "        print(f'summary has been generated and saved to: {output_file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated summary has been saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/english_summary_long/1000014343_cldn_sum.txt\n",
      "Translated summary has been saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/english_summary_long/1000014342_cldn_sum.txt\n",
      "Translated summary has been saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/english_summary_long/letter_school_hamburg_cldn_sum.txt\n",
      "Translated summary has been saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/english_summary_long/letter_arbeitsamt_internet_cldn_sum.txt\n",
      "Translated summary has been saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/english_summary_long/Ist-oder-soll_cldn_sum.txt\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import os\n",
    "\n",
    "# load the MarianMTModel and tokenizer for translation\n",
    "tokenizer_translate = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-de-en\")\n",
    "model_translate = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-de-en\")\n",
    "\n",
    "# function to translate German text to English\n",
    "def translate_to_english(german_text):\n",
    "    # tokenize the German text\n",
    "    inputs = tokenizer_translate(german_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    # generate English translation\n",
    "    translated = model_translate.generate(**inputs)\n",
    "    # decode the translated text\n",
    "    translated_text = tokenizer_translate.batch_decode(translated, skip_special_tokens=True)\n",
    "    return translated_text[0]\n",
    "\n",
    "# define input and output directories for German summaries\n",
    "input_directory_german = '/Users/carstenvolland/code/katia-si/better-letter/raw_data/german_summary_long/'\n",
    "output_directory_english = '/Users/carstenvolland/code/katia-si/better-letter/raw_data/english_summary_long/'\n",
    "\n",
    "# create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory_english):\n",
    "    os.makedirs(output_directory_english)\n",
    "\n",
    "# translate and save summaries for each file in the input directory\n",
    "for filename in os.listdir(input_directory_german):\n",
    "    # check if file is a text file\n",
    "    if filename.endswith('.txt'):\n",
    "        # read the German summary\n",
    "        with open(os.path.join(input_directory_german, filename), 'r', encoding='utf-8') as file:\n",
    "            german_summary = file.read()\n",
    "\n",
    "        # translate German summary to English\n",
    "        english_summary = translate_to_english(german_summary)\n",
    "\n",
    "        # construct the full path to the output file\n",
    "        output_file_path_english = os.path.join(output_directory_english, filename)\n",
    "\n",
    "        # write the translated summary to the output file\n",
    "        with open(output_file_path_english, 'w', encoding='utf-8') as output_file:\n",
    "            output_file.write(english_summary)\n",
    "\n",
    "        print(f'translated summary has been saved to: {output_file_path_english}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Differenz zwischen dem von den Eltern zu zahlenden Maximalpreis von 4,35 Euro und der neuen Preisobergrenze für die Caterer übernimmt die Schulbehörde. Das gilt für alle Mittagessen; auch die der vollzahlendsten Schülerinnen und Schülern. Damit setzt der Hamburger Senat konsequent die seit 2020 begonnene Linie durch. Mit freundlichen Grüßen Ihr Ganzirksame Ganztagsreferat pro state of the sun: Die Freie und Hansestadt Hamburg.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load BART model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Shahm/bart-german\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Shahm/bart-german\")\n",
    "\n",
    "# Define your original text\n",
    "original_text = \"\"\"\n",
    "Schulisches Mittagessen: Neuer Maximalpreis für das Schuljahr 2023/24 und neue Preisobergrenze für Caterer ab dem 01.08.2023 Sehr geehrte Eltern, mit diesem Schreiben möchten wir Sie darüber informieren; dass auf Basis der allgemeinen Preisentwicklung der von den Eltern zu zahlende Höchstpreis für das Mittagessen zum 1. August 2023 um 20 Cent auf 4,35 Euro angehoben wird. Angesichts der nach wie vor hohen Lebensmittelpreise deckt dieser Beitrag derzeit nicht die tatsächlichen Kosten für ein Mittagessen: Die Caterer können daher ab dem 01.08.2023 bis zu 4,80 Euro Mittagessen abrechnen Die Differenz zwischen dem von den Eltern zu zahlenden Maximalpreis von 4,35 Euro und der neuen Preisobergrenze für die Caterer übernimmt die Schulbehörde und rechnet die Differenz direkt mit den Caterern ab. Das gilt für alle Mittagessen; auch die der vollzahlenden Schülerinnen und Schüler. Damit setzt der Hamburger Senat konsequent die seit 2020 begonnene Linie durch; im Sinne der Familien; Kinder und Jugendlichen ein schulisches Mittagessen zu vertretbaren Preisen zu sichern und den an den Hamburger Schulen tätigen Cateringunternehmen angemessene Preise zu ermöglichen: Insgesamt übernehmen die Freie und Hansestadt Hamburg und der Bund deutlich mehr als 50 Prozent der Kosten aller schulischen Mittagessen, um für alle Schülerinnen und Schüler an Hamburgs Schulen ein gesundes Mittagessen zu gewährleisten: Mehr Informationen hierzu finden Sie bei Bedarf unter Mittaqessen_für_die_Hamburqer_Schulen hamburq de. Mit freundlichen Grüßen Ihr Ganztagsreferat pro\n",
    "\"\"\"\n",
    "\n",
    "# Generate summary with longer max_length\n",
    "def generate_summary_longer(text: str) -> str:\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "    summary_ids = model.generate(\n",
    "        inputs,\n",
    "        max_length=400,  # Increase max_length to make the summary longer\n",
    "        min_length=150,  # Adjust min_length accordingly\n",
    "        length_penalty=2.0,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Generate longer summary\n",
    "summary_longer = generate_summary_longer(original_text)\n",
    "\n",
    "# Print the longer summary\n",
    "print(summary_longer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
