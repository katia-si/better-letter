{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Ist-oder-soll.jpeg. Output file /Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text/Ist-oder-soll.txt already exists.\n",
      "Text from letter_school_hamburg.png has been saved in: /Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text/letter_school_hamburg.txt.\n",
      "Skipping letter_arbeitsamt_internet.jpeg. Output file /Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text/letter_arbeitsamt_internet.txt already exists.\n"
     ]
    }
   ],
   "source": [
    "### This part scans an image of letter and applies an OCR text recognition in order\n",
    "### to get the text of the image and transforms it to txt and stores it\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import easyocr\n",
    "import io\n",
    "\n",
    "def process_images(image_directory, output_directory):\n",
    "    \"\"\"\n",
    "    Process all images in the specified directory using OCR and save the extracted text to text files.\n",
    "\n",
    "    Args:\n",
    "        image_directory (str): Path to the directory containing the image files.\n",
    "        output_directory (str): Path to the directory where the output text files will be saved.\n",
    "    \"\"\"\n",
    "    # init the OCR reader\n",
    "    reader = easyocr.Reader(['de'])\n",
    "\n",
    "    # iterater through all files in the directory\n",
    "    for filename in os.listdir(image_directory):\n",
    "        # check if file is an image\n",
    "        if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "            # make the full path to the image file\n",
    "            image_path = os.path.join(image_directory, filename)\n",
    "\n",
    "            # open image for OCR\n",
    "            with open(image_path, 'rb') as image_file:\n",
    "                image_bytes = image_file.read()\n",
    "\n",
    "            # extract text from image using easyocr\n",
    "            result = reader.readtext(image_bytes)\n",
    "\n",
    "            # extracted text\n",
    "            text = '\\n'.join([entry[1] for entry in result])\n",
    "\n",
    "            # define output path to save extracted text\n",
    "            output_path = os.path.join(output_directory, f'{os.path.splitext(filename)[0]}.txt')\n",
    "\n",
    "            # check if output file already exists\n",
    "            if os.path.exists(output_path):\n",
    "                print(f\"Skipping {filename}. Output file {output_path} already exists.\")\n",
    "                continue\n",
    "\n",
    "            # save extracted text to a text file\n",
    "            with open(output_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(text)\n",
    "\n",
    "            # print a confirmation message about the text extraction\n",
    "            print(f'Text from {filename} has been saved in: {output_path}.')\n",
    "\n",
    "# define path to the directory containing the image files\n",
    "image_directory = '/Users/carstenvolland/code/katia-si/better-letter/text_extractor/data_images/'\n",
    "\n",
    "# define the path to the directory where the output text files will be saved\n",
    "output_directory = '/Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text'\n",
    "\n",
    "# porcess images in the specified directory\n",
    "process_images(image_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned text has been saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text_cleaned/letter_school_hamburg_cldn.txt\n",
      "Cleaned text has been saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text_cleaned/Ist-oder-soll_cldn.txt\n",
      "Cleaned text has been saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text_cleaned/letter_arbeitsamt_internet_cldn.txt\n"
     ]
    }
   ],
   "source": [
    "### function to clean the data so it looks like real sentences\n",
    "\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "def clean_extracted_text(text):\n",
    "    # handly hyphenated line breaks\n",
    "    text = re.sub(r'(\\w+)-\\n(\\w+)', r'\\1\\2', text)\n",
    "    # replace remaining newlines with spaces\n",
    "    text = text.replace('\\n', ' ')\n",
    "    # remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def clean_and_save_files(input_directory, output_directory):\n",
    "    # create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # iterate through all files in the input directory\n",
    "    for filename in os.listdir(input_directory):\n",
    "        # check if the file is a text file\n",
    "        if filename.endswith('.txt'):\n",
    "            # construct the full path to the input file\n",
    "            input_file_path = os.path.join(input_directory, filename)\n",
    "\n",
    "            # read the content of the input file\n",
    "            with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "                extracted_text = file.read()\n",
    "\n",
    "            # clean the extracted text\n",
    "            cleaned_text = clean_extracted_text(extracted_text)\n",
    "\n",
    "            # construct the full path to the output file\n",
    "            output_file_path = os.path.join(output_directory, filename.replace('.txt', '_cldn.txt'))\n",
    "\n",
    "            # write the cleaned text to the output file\n",
    "            with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(cleaned_text)\n",
    "\n",
    "            print(f'Cleaned text has been saved to: {output_file_path}')\n",
    "\n",
    "# define the input directory containing the extracted text files\n",
    "input_directory = '/Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text'\n",
    "\n",
    "# define the output directory where cleaned text files will be saved\n",
    "output_directory = '/Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text_cleaned'\n",
    "\n",
    "# clean and save text files in the input directory\n",
    "clean_and_save_files(input_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carstenvolland/.pyenv/versions/3.10.6/envs/better-letter/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated text has been saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/english_translation/letter_arbeitsamt_internet_cldn_en.txt\n",
      "Translated text has been saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/english_translation/Ist-oder-soll_cldn_en.txt\n",
      "Translated text has been saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/english_translation/letter_school_hamburg_cldn_en.txt\n"
     ]
    }
   ],
   "source": [
    "### translate the cleand letter text from german to english\n",
    "\n",
    "import os\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# load pre-trained model and tokenizer\n",
    "model_name = \"Helsinki-NLP/opus-mt-de-en\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# function to translate German text to English\n",
    "def translate_german_to_english(text):\n",
    "    # tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "\n",
    "    # perform translation\n",
    "    translated = model.generate(**inputs)\n",
    "\n",
    "    # decode the translated text\n",
    "    translated_text = tokenizer.batch_decode(translated, skip_special_tokens=True)[0]\n",
    "\n",
    "    return translated_text\n",
    "\n",
    "# define input and output directories\n",
    "input_directory = '/Users/carstenvolland/code/katia-si/better-letter/raw_data/german_ocr_text_cleaned'\n",
    "output_directory = '/Users/carstenvolland/code/katia-si/better-letter/raw_data/english_translation'\n",
    "\n",
    "# create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# translate and save each file in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    # check if the file is a text file\n",
    "    if filename.endswith('.txt'):\n",
    "        # construct the full path to the input file\n",
    "        input_file_path = os.path.join(input_directory, filename)\n",
    "\n",
    "        # read the content of the input file\n",
    "        with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "            german_text = file.read()\n",
    "\n",
    "        # rranslate german text to english\n",
    "        english_translation = translate_german_to_english(german_text)\n",
    "\n",
    "        # construct the full path to the output file\n",
    "        output_file_path = os.path.join(output_directory, filename.replace('.txt', '_en.txt'))\n",
    "\n",
    "        # write english translation to the output file\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "            output_file.write(english_translation)\n",
    "\n",
    "        print(f\"Translated text has been saved to: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary has been generated and saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/english_summary/letter_school_hamburg_cldn_en_sum.txt\n",
      "Summary has been generated and saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/english_summary/letter_arbeitsamt_internet_cldn_en_sum.txt\n",
      "Summary has been generated and saved to: /Users/carstenvolland/code/katia-si/better-letter/raw_data/english_summary/Ist-oder-soll_cldn_en_sum.txt\n"
     ]
    }
   ],
   "source": [
    "### summarizes the translated text data\n",
    "\n",
    "\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "import os\n",
    "\n",
    "# load pre-trained model and tokenizer\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# function to generate summary\n",
    "def generate_summary(text):\n",
    "    inputs = tokenizer([text], max_length=1024, return_tensors='pt', truncation=True)\n",
    "    summary_ids = model.generate(inputs['input_ids'], num_beams=4, min_length=30, max_length=200, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# define input and output directories\n",
    "input_directory = '/Users/carstenvolland/code/katia-si/better-letter/raw_data/english_translation'\n",
    "output_directory = '/Users/carstenvolland/code/katia-si/better-letter/raw_data/english_summary'\n",
    "\n",
    "# create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# generate summary for each file in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    # check if file is a text file\n",
    "    if filename.endswith('.txt'):\n",
    "        # construct the full path to the input file\n",
    "        input_file_path = os.path.join(input_directory, filename)\n",
    "\n",
    "        # read the content of the input file\n",
    "        with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        # generate summary\n",
    "        summary = generate_summary(text)\n",
    "\n",
    "        # construct the full path to the output file\n",
    "        output_file_path = os.path.join(output_directory, f'{os.path.splitext(filename)[0]}_sum.txt')\n",
    "\n",
    "        # write summary to the output file\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "            output_file.write(summary)\n",
    "\n",
    "        print(f\"Summary has been generated and saved to: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
